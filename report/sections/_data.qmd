
### 2. Data

We planned to acquire data from a publicly available dataset.

The dataset used for this project, titled "Estimation of Obesity Levels Based on Eating Habits and Physical Condition," was sourced from the UCI Machine Learning Repository.

This dataset, available in CSV, was originally compiled by researchers at the Universidad de la Costa, Colombia, and includes of both synthetically generated data and user-collected data. The 23% of the data was collected through a web page using a survey accesible online for 30 days, in which 498 individuals provided information regarding their dietary habits, physical activity levels, and demographic data. The remaining 77% of the dataset was generated synthetically using the SMOTE algorithm (Synthetic Minority Over-sampling Technique) in Weka. SMOTE was applied to balance the dataset, addressing issues of class imbalance by generating synthetic examples for minority classes.

At the end, the obtained dataset contains 17 attributes and 2111 records.

There are limitations and challenges associated with using this data. First, the reliance on synthetic data means that the results may not accurately represent real-world scenarios, as it lacks the nuances and variability present in genuine human behaviors. Second, while the user-collected data can provide valuable insights, it may be subject to biases, such as self-reporting inaccuracies and sampling biases, which can impact the reliability of our findings. Additionally, gathering data from diverse geographical regions might pose challenges in reaching a representative sample, and we must ensure that the survey is accessible and engaging to participants to encourage participation.

Below, the steps related to the conducted analyses will be outlined.

Import dataset.

```{r}
library(here)
dataset_raw <- read.csv(here("data/raw/dataset_raw.csv"))
head(dataset_raw)
```

Load required libraries for data manipulation, visualization, and clustering.
Each package serves a specific purpose:

- dplyr: For data manipulation (e.g., filtering, summarizing).
- tidyr: For data tidying (e.g., reshaping).
- ggplot2: For visualization.
- corrplot: For correlation matrix visualization.
- ggridges: For creating ridge plots.
- cluster: For clustering algorithms.
- reshape2: For data reshaping, especially during visualization.

```{r, message=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(corrplot)
library(ggridges)
library(cluster)
library(reshape2)
```

#### 2.1 Preprocessing analyses and checks

We rename columns for clarity and ease of use in the analysis.
The new names are shorter and more intuitive while preserving their original meaning.

```{r}
  dataset <- dataset_raw %>%
  rename(
    family_hist = family_history_with_overweight,
    obesity_lev = NObeyesdad,
    caloric_food = FAVC,
    vegetable_food = FCVC,
    nb_meal_day = NCP,
    food_btw_meals = CAEC,
    ch2o = CH2O,
    smoke = SMOKE,
    calorie_check = SCC,
    physical_act = FAF,
    freq_alcohol = CALC,
    use_tech = TUE,
    m_trans = MTRANS,
    gender = Gender,
    age = Age,
    weight = Weight,
    height = Height
  )
```

Check for missing values in the dataset, missing values are identified by counting NA values for each column.

```{r}
missing_values <- colSums(is.na(dataset))
missing_values
```

Missing values are identified by counting NA values for each column.
All columns contain complete data, with no missing values. If missing data were present, we could address it by either removing rows with missing values using dataset <- na.omit(dataset_row) or imputing missing values with appropriate measures (e.g. mean or median).

Check the structure of the dataset to identify data types for each variable.
This helps in identifying columns that need to be converted or standardized.

```{r}
str(dataset)
```

We convert specific columns to factors for categorical interpretation during analysis.
Factors ensure proper handling of discrete variables in statistical modeling.

We arranged the levels of the obesity categories, food consumption between meals, and the frequency of alcohol use to follow a logical ordinal progression, ensuring these variables accurately reflect increasing severity or frequency for improved interpretability and analysis.

```{r}
dataset <- dataset %>%
  mutate(
    gender = as.factor(gender),
    family_hist = as.factor(family_hist),
    caloric_food = as.factor(caloric_food),
    smoke = as.factor(smoke),
    calorie_check = as.factor(calorie_check),
    m_trans = as.factor(m_trans),
    obesity_lev = factor(obesity_lev, 
                         levels = c("Insufficient_Weight", "Normal_Weight", 
                                    "Overweight_Level_I", "Overweight_Level_II", 
                                    "Obesity_Type_I", "Obesity_Type_II", "Obesity_Type_III"), 
                         ordered = TRUE),
    food_btw_meals = factor(ifelse(food_btw_meals == "no", "No", food_btw_meals), 
                            levels = c("No", "Sometimes", "Frequently", "Always"), 
                            ordered = TRUE),
    freq_alcohol = factor(ifelse(freq_alcohol == "no", "No", freq_alcohol), 
                          levels = c("No", "Sometimes", "Frequently", "Always"), 
                          ordered = TRUE))
```

Using str() before and after confirms that each variable has the correct data type, preventing errors during analysis.

```{r}
str(dataset)
```

Check for duplicated rows in the dataset.

```{r}
duplicated_rows <- sum(duplicated(dataset))
duplicated_rows
```

Keep only one instance of each duplicated row.

```{r}
dataset <- dataset %>%
  distinct()
```

Check the number of rows after removing duplicates.

```{r}
nrow(dataset)
any(duplicated(dataset))
```

#### 2.2 In-depth analysis of SMOTE's impact and visualization of class Distribution

```{r}
ggplot(dataset, aes(x = obesity_lev)) +
  geom_bar(fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(
    title = "Class Distribution of Obesity Levels",
    x = "Obesity Level",
    y = "Count"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) #Adjusted the text for clarity
```

After applying SMOTE, the distribution is noticeably more balanced across all categories,  with each class showing a similar count. This outcome reflects SMOTE's intended effect of addressing class imbalance.

#### 2.3 Distribution analysis

Density plot for age.

```{r, warning=FALSE}
ggplot(dataset, aes(x = age, fill = obesity_lev)) +
  geom_density(alpha = 0.5) +
  theme_minimal() +
    labs(
    title = "Age Distribution by Obesity Levels",
    x = "Age",
    y = "Density",
    fill = "Obesity Level") +
  xlim(14, 50) # Limit the x-axis to 0–50
```

This graph allows us to assess the age distribution across obesity levels and to evaluate the impact of the SMOTE algorithm in generating synthetic data. Two key takeaways emerge: first, the distributions show a clear separation between obesity categories, particularly with younger ages dominating in lower obesity levels (e.g., Insufficient Weight and Normal Weight) and older ages appearing more prominently in higher obesity levels (e.g., Obesity Type II and III). Second, sharp peaks, such as the one around age 30 in "Obesity Type I," could signal potential artifacts from data synthesis. While these patterns indicate that the dataset maintains logical trends, further validation is necessary to confirm that these separations and peaks reflect realistic population characteristics and not artificial biases introduced during data augmentation. Overall, the dataset appears well-structured, but these observations warrant careful consideration during analysis.

Summary statistics by obesity level.

```{r}
dataset %>%
  group_by(obesity_lev) %>%
  summarize(
    Age_Mean = mean(age, na.rm = TRUE),
    Age_SD = sd(age, na.rm = TRUE),
    Height_Mean = mean(height, na.rm = TRUE),
    Height_SD = sd(height, na.rm = TRUE),
    Weight_Mean = mean(weight, na.rm = TRUE),
    Weight_SD = sd(weight, na.rm = TRUE)
  )
```

The summary statistics show relatively consistent means and standard deviations for Age, Height, and Weight across obesity levels, which suggests that SMOTE has preserved the overall distribution without introducing extreme values. Interpretation: Since the means and standard deviations are similar across classes, it appears SMOTE didn’t drastically alter the dataset's variability. This consistency supports the idea that SMOTE effectively balanced the classes without distorting key variable distributions.

Perform K-means clustering and calculate silhouette score.

```{r}
library(cluster)
set.seed(123)
kmeans_res <- kmeans(select(dataset, where(is.numeric)), centers = length(unique(dataset$obesity_lev)))
silhouette_score <- silhouette(kmeans_res$cluster, dist(select(dataset, where(is.numeric))))
mean_silhouette_score <- mean(silhouette_score[, "sil_width"])
mean_silhouette_score
```

Silhouette Score from K-means Clustering: The mean silhouette score of approximately 0.456 suggests a moderate level of cohesion within clusters and some separation between them. This score indicates that the clusters (representing obesity levels) are neither too distinct nor too blended. Interpretation: A score close to 0.5 generally reflects reasonable class separability without excessive artificial separability. This score suggests that SMOTE has helped create distinguishable but not overly isolated clusters, which is desirable for class balance. We conclude that SMOTE has balanced the dataset without drastically distorting it.

Creating a Numerical Dataset "dataset_num".

```{r}

dataset_num <- dataset %>%
  mutate(obesity_lev = recode(obesity_lev,
                              "Insufficient_Weight"=1,
                              "Normal_Weight" = 2,
                              "Overweight_Level_I" = 3,
                              "Overweight_Level_II" = 4,
                              "Obesity_Type_I" = 5,
                              "Obesity_Type_II" = 6,
                              "Obesity_Type_III" = 7,
  ))

dataset_num <- dataset %>%
  mutate(freq_alcohol = recode(freq_alcohol,
                               "No"=1,        
                               "Sometimes"=2, 
                               "Frequently" =3,
                               "Always"  =4 
  ))

dataset_num <- dataset %>%
  mutate(m_trans = recode(m_trans,
                          "Automobile"=1,
                          "Bike"=2,
                          "Motorbike"=3,
                          "Public_Transportation"=4,
                          "Walking"=5,
  ))

dataset_num <- dataset %>%
  mutate(food_btw_meals = recode(food_btw_meals,
                                 "No"=0,
                                 "Sometimes"=1 ,
                                 "Frequently"=2,
                                 "Always"=3
  )
  )

dataset_num <- dataset_num%>%
  mutate(calorie_check = recode(calorie_check,
                                "no"=0,
                                "yes"=1 ,
  ))

dataset_num <- dataset_num %>%
  mutate(across(where(is.factor), ~ as.numeric(.)))

str(dataset_num)

head(dataset_num)
```
We verified the presence of any potential NA values that might have arisen during the conversion of categorical variables to numeric format. 

```{r}
colSums(is.na(dataset_num))
```

The results of the test confirmed that there are no NA values in the dataset, indicating that all variables were successfully converted to numeric format while retaining their integrity.


#### 2.4 Correlations

In order to select the possible factor influencing obesity level.

We computed a correlation matrix to analyze the relationships between numeric variables, focusing on their associations with obesity_lev. Variables were reordered by the strength of their correlation with obesity_lev for clarity. A heatmap was generated using a diverging color gradient to visualize these correlations, with red indicating strong positive relationships, blue for negative, and white for weak or neutral. Numerical labels and rotated axis labels were added to improve interpretability, highlighting key factors linked to obesity levels.

```{r}
#Assuming dataset_num is already defined and contains the relevant columns
cor_matrix <- cor(dataset_num %>%
                    select("physical_act", "freq_alcohol", "obesity_lev", "age",
                           "weight","height", "family_hist", "caloric_food",
                           "vegetable_food", "food_btw_meals", "use_tech", "ch2o",
                           "m_trans", "smoke","nb_meal_day", "calorie_check",
                           "gender"),
                  use = "complete.obs")

#Extract the correlations with 'obesity_lev'
cor_with_obesity_lev <- cor_matrix["obesity_lev",]

#Order variables by their correlation with 'obesity_lev'
ordered_vars <- names(sort(cor_with_obesity_lev, decreasing = TRUE))

#Reorder the correlation matrix based on this order
cor_matrix_ordered <- cor_matrix[ordered_vars, ordered_vars]

#Melt the ordered correlation matrix into long format
cor_long <- melt(cor_matrix_ordered)

ggplot(cor_long, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  geom_text(aes(label = round(value, 2)), color = "black", size = 2.5, vjust = 0.5
            , hjust = 0.5) + # Center text within tiles
    scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
  
  labs(title = "Correlation Heatmap Ordered by Obesity Level", x = "Variables", y
       = "Variables") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        # Rotate x-axis labels for readability
        axis.text.y = element_text(angle = 45, vjust = 1) 
        # Rotate y-axis labels for readability
  )

# Create the heatmap with correlation values

# Assuming dataset_num is already defined and contains the relevant columns
cor_matrix <- cor(dataset_num %>%
                    select("physical_act", "freq_alcohol", "obesity_lev", "age",
                           "weight", "family_hist", "caloric_food",
                           "vegetable_food", "food_btw_meals",
                           "use_tech","ch2o", "height",
                           "calorie_check", "gender"),
                  use = "complete.obs")

# Extract the correlations with 'obesity_lev'
cor_with_obesity_lev <- cor_matrix["obesity_lev",]

# Order variables by their correlation with 'obesity_lev'
ordered_vars <- names(sort(cor_with_obesity_lev, decreasing = TRUE))

# Reorder the correlation matrix based on this order
cor_matrix_ordered <- cor_matrix[ordered_vars, ordered_vars]

# Melt the ordered correlation matrix into long format
cor_long <- melt(cor_matrix_ordered)


ggplot(cor_long, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  geom_text(aes(label = round(value, 2)), color = "black", size = 2.5, vjust = 0.5
            , hjust = 0.5) + # Center text within tiles
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
  labs(title = "Correlation Heatmap Ordered by Obesity Level", x = "Variables", y
       = "Variables") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        # Rotate x-axis labels for readability
        axis.text.y = element_text(angle = 45, vjust = 1) 
        # Rotate y-axis labels for readability
  )
```
